{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "We will be creating an argumentative chatbot based on this dataset: https://nlds.soe.ucsc.edu/iac "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Create the raw input-output pairs from the dataset \n",
    "\n",
    "We begin by converting the arguments dataset into a format useful to us. The dataset contains various features, but we're primarily concerned with creating parent-child (statement-response or input-output) post pairs. Because the posts are not necessarily replying to their direct predecessor in the discussion (and thus in the JSON), we will have to keep track of the post id and parent id for each post to create pairings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building metadata (Part 1/2)...\n",
      "Processing file 0 of 11800...\n",
      "Processing file 1180 of 11800...\n",
      "Processing file 2360 of 11800...\n",
      "Processing file 3540 of 11800...\n",
      "Processing file 4720 of 11800...\n",
      "Processing file 5900 of 11800...\n",
      "Processing file 7080 of 11800...\n",
      "Processing file 8260 of 11800...\n",
      "Processing file 9440 of 11800...\n",
      "Processing file 10620 of 11800...\n",
      "Saving metadata (Part 2/2)...\n",
      "Finished processing files!\n",
      "Total elapsed time: 6.684291124343872\n"
     ]
    }
   ],
   "source": [
    "id_to_text = {}\n",
    "parent_to_child_ids = []\n",
    "my_data_dir = \"./data/\"\n",
    "my_data_dir_full = os.path.join(os.getcwd(), my_data_dir)\n",
    "if not os.path.isdir(my_data_dir_full):\n",
    "    os.mkdir(my_data_dir_full)\n",
    "build_pairs = True\n",
    "\n",
    "if build_pairs:\n",
    "    data_dir = \"./iac_v1.1/data/fourforums/discussions/\"\n",
    "    \n",
    "    discussion_filepaths = [os.path.join(data_dir, file) for file in os.listdir(data_dir)]\n",
    "\n",
    "    print(\"Building metadata (Part 1/2)...\")\n",
    "    curr_file_num = 0\n",
    "    start_time = time.time()\n",
    "    for discussion_filepath in discussion_filepaths:\n",
    "        if curr_file_num % (len(discussion_filepaths)//10) == 0:\n",
    "            print(\"Processing file {} of {}...\".format(curr_file_num, len(discussion_filepaths)))\n",
    "        curr_file_num += 1\n",
    "        with open(discussion_filepath, 'r') as discussion_file:\n",
    "            discussion = json.load(discussion_file)[0]\n",
    "            for post in discussion:\n",
    "                post_id = post[0]\n",
    "                post_parent_id = post[5]\n",
    "                post_text = post[3]\n",
    "                id_to_text[post_id] = post_text\n",
    "                if post_parent_id:\n",
    "                    parent_to_child_ids.append((post_parent_id, post_id))\n",
    "\n",
    "    print(\"Saving metadata (Part 2/2)...\")\n",
    "    with open(os.path.join(my_data_dir, 'id_to_text.pkl'), 'wb') as id_to_text_file:\n",
    "        pickle.dump(id_to_text, id_to_text_file, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "    with open(os.path.join(my_data_dir, 'parent_to_child_ids.pkl'), 'wb') as parent_to_child_ids_file:\n",
    "        pickle.dump(parent_to_child_ids, parent_to_child_ids_file, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    print(\"Finished processing files!\\nTotal elapsed time: {}\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Convert raw input-output pairs into feedable format for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import torchtext\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import sklearn.model_selection\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(my_data_dir, 'id_to_text.pkl'), 'rb') as id_to_text_file:\n",
    "    id_to_text = pickle.load(id_to_text_file)\n",
    "\n",
    "with open(os.path.join(my_data_dir, 'parent_to_child_ids.pkl'), 'rb') as parent_to_child_ids_file:\n",
    "    parent_to_child_ids = pickle.load(parent_to_child_ids_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean post length: 193.52459662557845\n",
      "Min post length: 1\n",
      "Max post length: 12347\n",
      "Post length standard deviation: 292.1808739716809\n",
      "Percentage of posts shorter than 200 words: 0.717584155780335\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "post_lengths = {post_id: len(post.split(' ')) for post_id, post  in id_to_text.items()}\n",
    "\n",
    "print(\"Mean post length: {}\".format(np.mean(list(post_lengths.values()))))\n",
    "print(\"Min post length: {}\".format(np.min(list(post_lengths.values()))))\n",
    "print(\"Max post length: {}\".format(np.max(list(post_lengths.values()))))\n",
    "print(\"Post length standard deviation: {}\".format(np.std(list(post_lengths.values()))))\n",
    "\n",
    "max_post_length = 200\n",
    "print(\"Percentage of posts shorter than {} words: {}\".format(max_post_length, np.mean([post_length < max_post_length for post_length in post_lengths.values()])))\n",
    "plt.hist(list(post_lengths.values()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ratio: 2.9412882069147175\n",
      "Min ratio: 0.00038299502106472615\n",
      "Max ratio: 4746.0\n",
      "Ratio standard deviation: 19.61325095885775\n",
      "Percentage of ratios greater than 3: 0.16417087177754788\n",
      "Percentage of ratios less than 0.33: 0.11400776977809683\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "post_length_ratios = [post_lengths[parent_id]/post_lengths[child_id] for parent_id, child_id in parent_to_child_ids]\n",
    "\n",
    "print(\"Mean ratio: {}\".format(np.mean(post_length_ratios)))\n",
    "print(\"Min ratio: {}\".format(np.min(post_length_ratios)))\n",
    "print(\"Max ratio: {}\".format(np.max(post_length_ratios)))\n",
    "print(\"Ratio standard deviation: {}\".format(np.std(post_length_ratios)))\n",
    "\n",
    "max_post_length_ratio = 3\n",
    "min_post_length_ratio = 0.33\n",
    "print(\"Percentage of ratios greater than {}: {}\".format(max_post_length_ratio, np.mean([post_length_ratio > max_post_length_ratio for post_length_ratio in post_length_ratios])))\n",
    "print(\"Percentage of ratios less than {}: {}\".format(min_post_length_ratio, np.mean([post_length_ratio < min_post_length_ratio for post_length_ratio in post_length_ratios])))\n",
    "plt.hist(post_length_ratios)\n",
    "plt.show()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def light_tokenizer(post):\n",
    "    return [token.text for token in nlp(post, disable=['parser', 'tagger', 'ner'])]\n",
    "\n",
    "post_field = torchtext.data.Field(tokenize=light_tokenizer, init_token='<sos>', eos_token='<eos>', lower=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of data retained: 45.765945991596816\n"
     ]
    }
   ],
   "source": [
    "build_csv = True\n",
    "\n",
    "if build_csv:\n",
    "    with open(os.path.join(my_data_dir, 'id_to_text.pkl'), 'rb') as id_to_text_file:\n",
    "        id_to_text = pickle.load(id_to_text_file)\n",
    "\n",
    "    with open(os.path.join(my_data_dir, 'parent_to_child_ids.pkl'), 'rb') as parent_to_child_ids_file:\n",
    "        parent_to_child_ids = pickle.load(parent_to_child_ids_file)\n",
    "\n",
    "    pairs = {'parent_post': [], 'child_post': []}\n",
    "    for parent_post_id, child_post_id in parent_to_child_ids:\n",
    "        parent_post_length = len(id_to_text[parent_post_id].split(' '))\n",
    "        child_post_length = len(id_to_text[child_post_id].split(' '))\n",
    "        \n",
    "        if parent_post_length < max_post_length and child_post_length < max_post_length and parent_post_length/child_post_length <= max_post_length_ratio and parent_post_length/child_post_length >= min_post_length_ratio:\n",
    "            # TODO: check for large difference in post length\n",
    "            pairs['parent_post'].append(id_to_text[parent_post_id])\n",
    "            pairs['child_post'].append(id_to_text[child_post_id])\n",
    "\n",
    "    print(\"Percentage of data retained: {}\".format(len(pairs['parent_post']) *100 / len(parent_to_child_ids)))\n",
    "    pairs_df = pd.DataFrame(pairs, columns=['parent_post', 'child_post'])\n",
    "    train, test = sklearn.model_selection.train_test_split(pairs_df, test_size=0.2)\n",
    "\n",
    "    train.to_csv(os.path.join(my_data_dir, 'train.csv'), index=False)\n",
    "    test.to_csv(os.path.join(my_data_dir, 'test.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building datasets...\n",
      "Datasets built! Time elapsed: 198.88171911239624\n",
      "Building vocabulary...\n",
      "Vocabulary built! Time elapsed: 4.872278928756714\n",
      "Vocabulary size: 91919\n"
     ]
    }
   ],
   "source": [
    "print(\"Building datasets...\")\n",
    "dataset_start_time = time.time()\n",
    "pair_fields = [('parent_post', post_field), ('child_post', post_field)]\n",
    "train_set, test_set = torchtext.data.TabularDataset.splits(path=my_data_dir, train='train.csv', test='test.csv', format='csv', fields=pair_fields)\n",
    "print(\"Datasets built! Time elapsed: {}\".format(time.time()-dataset_start_time))\n",
    "\n",
    "print(\"Building vocabulary...\")\n",
    "vocab_start_time = time.time()\n",
    "post_field.build_vocab(train_set, min_freq=2)\n",
    "print(\"Vocabulary built! Time elapsed: {}\".format(time.time()-vocab_start_time))\n",
    "print(\"Vocabulary size: {}\".format(len(post_field.vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "cpu_device = torch.device('cpu')\n",
    "train_set_iterator, test_set_iterator = torchtext.data.BucketIterator.splits((train_set, test_set), batch_size=16, device=device, shuffle=True, sort_key=lambda pair: len(pair.parent_post))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Create the seq2seq model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqEncoder(torch.nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_layer_size, num_hidden_layers, dropout_rate):\n",
    "        super(Seq2SeqEncoder, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = torch.nn.LSTM(embedding_size, hidden_layer_size, num_hidden_layers, dropout=dropout_rate)\n",
    "        self.dropout = torch.nn.Dropout(dropout_rate)\n",
    "        \n",
    "    def forward(self, encoder_input):\n",
    "        output, (hidden_state, cell) = self.rnn(self.dropout(self.embedding(encoder_input)))\n",
    "        return hidden_state, cell\n",
    "        \n",
    "class Seq2SeqDecoder(torch.nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_layer_size, num_hidden_layers, output_size, dropout_rate):\n",
    "        super(Seq2SeqDecoder, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = torch.nn.LSTM(embedding_size, hidden_layer_size, num_hidden_layers, dropout=dropout_rate)\n",
    "        self.output_size = output_size\n",
    "        self.out = torch.nn.Linear(hidden_layer_size, output_size)\n",
    "        self.dropout = torch.nn.Dropout(dropout_rate)\n",
    "    \n",
    "    def forward(self, decoder_input, hidden_state, cell):\n",
    "        output, (hidden_state, cell) = self.rnn(self.dropout(self.embedding(decoder_input.unsqueeze(0))), (hidden_state, cell))\n",
    "        return self.out(output.squeeze(0)), hidden_state, cell \n",
    "    \n",
    "class Seq2Seq(torch.nn.Module):\n",
    "    def __init__(self, encoder_net, decoder_net):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder_net = encoder_net\n",
    "        self.decoder_net = decoder_net\n",
    "        \n",
    "    def forward(self, source, target, teacher_forcing_ratio=0.5):\n",
    "        batch_size = target.shape[1]\n",
    "        max_len = target.shape[0]\n",
    "        vocab_size = self.decoder_net.output_size\n",
    "        s2s_outputs = torch.zeros(max_len, batch_size, vocab_size).to(device)\n",
    "        \n",
    "        hidden_state, cell = self.encoder_net(source)\n",
    "        decoder_input = target[0,:]\n",
    "        for token_index in range(1, max_len):\n",
    "            output, hidden_state, cell = self.decoder_net(decoder_input, hidden_state, cell)\n",
    "            s2s_outputs[token_index] = output\n",
    "            if random.random() < teacher_forcing_ratio:\n",
    "                decoder_input = target[token_index]\n",
    "            else:\n",
    "                decoder_input = output.argmax(1)\n",
    "        \n",
    "        return s2s_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "input_size = output_size = len(post_field.vocab)\n",
    "embedding_size = 128\n",
    "hidden_layer_size = 256\n",
    "num_hidden_layers = 2\n",
    "dropout_rate = 0.5\n",
    "\n",
    "# print(torch.cuda.memory_allocated(device=0)/(10**9))\n",
    "encoder_net = Seq2SeqEncoder(input_size, embedding_size, hidden_layer_size, num_hidden_layers, dropout_rate)\n",
    "# print(torch.cuda.memory_allocated(device=0)/(10**9))\n",
    "decoder_net = Seq2SeqDecoder(input_size, embedding_size, hidden_layer_size, num_hidden_layers, output_size, dropout_rate)\n",
    "# print(torch.cuda.memory_allocated(device=0)/(10**9))\n",
    "seq2seq_net = Seq2Seq(encoder_net, decoder_net).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Train the seq2seq model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(seq2seq_net.parameters())\n",
    "padding_index = post_field.vocab.stoi['<pad>']\n",
    "loss_function = torch.nn.CrossEntropyLoss(ignore_index=padding_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_directory = os.path.join(os.getcwd(), my_data_dir, 'models/')\n",
    "if not os.path.isdir(models_directory):\n",
    "    os.mkdir(models_directory)\n",
    "\n",
    "run_name = \"v3-small\"\n",
    "run_models_directory = os.path.join(os.getcwd(), my_data_dir, 'models/{}'.format(run_name))\n",
    "if not os.path.isdir(run_models_directory):\n",
    "    os.mkdir(run_models_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_clip = 1\n",
    "def train(seq2seq_net, train_set_iterator, optimizer, loss_function, max_clip, writer, epoch_num):\n",
    "    seq2seq_net.train()\n",
    "    total_loss = 0\n",
    "    time_train = time.time()\n",
    "    inner_min_loss = float('inf')\n",
    "    iterator_length = len(train_set_iterator)\n",
    "    for i, batch in enumerate(train_set_iterator):\n",
    "        parent_post = batch.parent_post\n",
    "        child_post = batch.child_post\n",
    "        if i % 10 == 0:\n",
    "            print('train: {} of {} in epoch {}'.format(i, iterator_length, epoch_num))\n",
    "#         print('1', torch.cuda.memory_allocated(device=0)/(10**9))\n",
    "        optimizer.zero_grad()\n",
    "        response = seq2seq_net(parent_post, child_post, 0.5)\n",
    "#         print('2', torch.cuda.memory_allocated(device=0)/(10**9))\n",
    "        response = response[1:].view(-1, response.shape[-1])\n",
    "        child_post = child_post[1:].view(-1)\n",
    "        \n",
    "        loss = loss_function(response, child_post)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(seq2seq_net.parameters(), max_clip)\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        inner_loss_scalar = loss.detach().to(cpu_device).numpy().squeeze()\n",
    "#         print('3', torch.cuda.memory_allocated(device=0)/(10**9))\n",
    "#         response = response.detach()\n",
    "#         del response\n",
    "        if i % (len(train_set_iterator) // 10) == 0 or i == len(train_set_iterator) - 1:\n",
    "            writer.add_scalar('Loss/train', inner_loss_scalar, epoch_num*len(train_set_iterator)+i)\n",
    "            if (inner_loss_scalar < inner_min_loss):\n",
    "                torch.save(seq2seq_net.state_dict(), os.path.join(my_data_dir, 'models/{}/best-inner-model-train-{}.pt'.format(run_name, epoch_num)))\n",
    "                torch.save(encoder_net.state_dict(), os.path.join(my_data_dir, 'models/{}/best-encoder-inner-model-train-{}.pt'.format(run_name, epoch_num)))\n",
    "                torch.save(decoder_net.state_dict(), os.path.join(my_data_dir, 'models/{}/best-decoder-inner-model-train-{}.pt'.format(run_name, epoch_num)))\n",
    "                lowest_loss_train = inner_loss_scalar\n",
    "            \n",
    "        print(\"total time for epoch so far: {}\".format(time.time() - time_train))\n",
    "    \n",
    "    return total_loss/len(train_set_iterator)\n",
    "\n",
    "def test(seq2seq_net, test_set_iterator, loss_function, writer, epoch_num):\n",
    "    seq2seq_net.eval()\n",
    "    total_loss = 0\n",
    "    time_test = time.time()\n",
    "    iterator_length = len(test_set_iterator)\n",
    "    for i, batch in enumerate(test_set_iterator):\n",
    "        parent_post = batch.parent_post\n",
    "        child_post = batch.child_post\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print('test: {} of {} in epoch {}'.format(i, iterator_length, epoch_num))\n",
    "#         print('1', torch.cuda.memory_allocated(device=0)/(10**9))\n",
    "        response = seq2seq_net(parent_post, child_post, 0)\n",
    "#         print('2', torch.cuda.memory_allocated(device=0)/(10**9))\n",
    "        response = response[1:].view(-1, response.shape[-1])\n",
    "        child_post = child_post[1:].view(-1)\n",
    "        \n",
    "        loss = loss_function(response, child_post)\n",
    "        total_loss += loss.item()\n",
    "        print(\"total time for epoch so far: {}\".format(time.time() - time_train))\n",
    "#         response = response.detach()\n",
    "#         del response\n",
    "#         print('3', torch.cuda.memory_allocated(device=0)/(10**9))\n",
    "        if i % (len(test_set_iterator) // 10) == 0:\n",
    "            writer.add_scalar('Loss/test', loss.detach().to(cpu_device).numpy().squeeze(), epoch_num*len(test_set_iterator)+i)\n",
    "        \n",
    "    return total_loss/len(test_set_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = torch.utils.tensorboard.SummaryWriter(log_dir=os.path.join(my_data_dir, \"runs/{}\".format(run_name)))\n",
    "num_epochs = 10\n",
    "\n",
    "lowest_loss_train = float('inf')\n",
    "lowest_loss_test = float('inf')\n",
    "print(torch.cuda.memory_allocated(device=0)/(10**9))\n",
    "print(\"Beginning training...\")\n",
    "training_start_time = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"Starting epoch {}...\".format(epoch))\n",
    "    \n",
    "    epoch_start_time = time.time()\n",
    "    loss_train = train(seq2seq_net, train_set_iterator, optimizer, loss_function, max_clip, writer, epoch)\n",
    "    print(\"epoch train\", torch.cuda.memory_allocated(device=0)/(10**9))\n",
    "    loss_test = test(seq2seq_net, test_set_iterator, loss_function, writer, epoch)\n",
    "    print(\"epoch test\", torch.cuda.memory_allocated(device=0)/(10**9))\n",
    "    loss_train_scalar = loss_train.detach().to(cpu_device).numpy().squeeze()\n",
    "    loss_test_scalar = loss_test.detach().to(cpu_device).numpy().squeeze()\n",
    "    writer.add_scalar('Loss/train', loss_train_scalar, epoch)\n",
    "    writer.add_scalar('Loss/test', loss_test_scalar, epoch)\n",
    "    \n",
    "    print(\"Epoch training duration: {}\".format(time.time()-epoch_start_time))\n",
    "    print(\"Updating models...\")\n",
    "    \n",
    "    if loss_train_scalar <= lowest_loss_train:\n",
    "        torch.save(seq2seq_net.state_dict(), os.path.join(my_data_dir, 'models/{}/best-model-train.pt'.format(run_name)))\n",
    "        torch.save(encoder_net.state_dict(), os.path.join(my_data_dir, 'models/{}/best-encoder-model-train.pt'.format(run_name)))\n",
    "        torch.save(decoder_net.state_dict(), os.path.join(my_data_dir, 'models/{}/best-decoder-model-train.pt'.format(run_name)))\n",
    "        lowest_loss_train = loss_train_scalar\n",
    "    if loss_test_scalar <= lowest_loss_test:\n",
    "        torch.save(seq2seq_net.state_dict(), os.path.join(my_data_dir, 'models/{}/best-model-test.pt'.format(run_name)))\n",
    "        torch.save(encoder_net.state_dict(), os.path.join(my_data_dir, 'models/{}/best-encoder-model-test.pt'.format(run_name)))\n",
    "        torch.save(decoder_net.state_dict(), os.path.join(my_data_dir, 'models/{}/best-decoder-model-test.pt'.format(run_name)))\n",
    "        lowest_loss_test = loss_test_scalar\n",
    "    \n",
    "    print(\"Total elapsed time: {}\".format(time.time()-training_start_time))\n",
    "    \n",
    "\n",
    "print(\"Finished training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
